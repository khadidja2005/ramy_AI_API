{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBpbOJCUAeID",
        "outputId": "171f1d53-c4c6-495e-a79a-e2656c69a751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.75-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.75-py3-none-any.whl (914 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.75 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train the model\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model (pre-trained)\n",
        "model = YOLO(\"yolov8n.pt\")  # You can also try 'yolov8s.pt' or 'yolov8m.pt' for better accuracy\n",
        "\n",
        "# Train the model on your dataset\n",
        "model.train(\n",
        "    data=\"/content/rayonnage/data.yaml\",  # Path to your dataset config file\n",
        "    epochs=50,  # Increase for better accuracy\n",
        "    batch=16,  # Adjust based on GPU\n",
        "    imgsz=640,  # Resize images for training\n",
        "    device=\"cuda\"  # Use \"cuda\" if you have a GPU, otherwise use \"cpu\"\n",
        ")\n",
        "model.val()\n",
        "results = model.predict(source=\"/content/rayonnage/test/images/WhatsApp-Image-2025-02-05-a-10_07_51_81497b02_jpg.rf.ec7a60ce73b07828912115bc11e669d2.jpg\", save=True, conf=0.5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1E6Dw0dAygC",
        "outputId": "1411c49e-c315-4d67-e4c2-21bd026125a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.75 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/rayonnage/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 22.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 86.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/rayonnage/train/labels... 84 images, 0 backgrounds, 0 corrupt: 100%|██████████| 84/84 [00:00<00:00, 1501.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/rayonnage/train/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/rayonnage/valid/labels... 8 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<00:00, 575.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/rayonnage/valid/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50      4.47G      2.435      3.783       1.86        461        640: 100%|██████████| 6/6 [00:05<00:00,  1.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539     0.0642      0.461     0.0538     0.0301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50      4.65G       2.13       3.54      1.612        356        640: 100%|██████████| 6/6 [00:01<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.125      0.448      0.128     0.0722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50      5.14G      1.944      2.887       1.41        496        640: 100%|██████████| 6/6 [00:01<00:00,  4.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.162      0.638      0.376      0.195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50      4.67G      2.001       2.51      1.335        387        640: 100%|██████████| 6/6 [00:01<00:00,  3.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.921      0.337      0.517      0.256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50      5.15G      1.955      2.169      1.279        549        640: 100%|██████████| 6/6 [00:01<00:00,  4.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539       0.73      0.482      0.526      0.279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50      4.98G      1.961      1.993      1.282        433        640: 100%|██████████| 6/6 [00:01<00:00,  4.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.533      0.499      0.502      0.242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50      4.92G      1.919       1.91       1.31        202        640: 100%|██████████| 6/6 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.437      0.517      0.465       0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50      4.98G      1.945      1.686      1.306        421        640: 100%|██████████| 6/6 [00:01<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.402      0.623      0.459      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50      5.36G      1.874       1.57      1.301        378        640: 100%|██████████| 6/6 [00:01<00:00,  3.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.426      0.576      0.473      0.257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50      4.66G      1.899      1.576      1.249        433        640: 100%|██████████| 6/6 [00:01<00:00,  3.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.483       0.52      0.478      0.249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50      4.95G      1.922      1.516        1.3        282        640: 100%|██████████| 6/6 [00:01<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539       0.45      0.526       0.43      0.223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50       3.9G      1.934      1.473      1.299        579        640: 100%|██████████| 6/6 [00:01<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.355      0.724      0.424      0.213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50      5.02G      1.877      1.448      1.303        372        640: 100%|██████████| 6/6 [00:01<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.443      0.546      0.457      0.229\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50       4.2G      1.816      1.339       1.28        410        640: 100%|██████████| 6/6 [00:01<00:00,  3.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.471       0.62      0.486      0.264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50      3.81G      1.759      1.348      1.272        494        640: 100%|██████████| 6/6 [00:01<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.477      0.633      0.515      0.276\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50      4.64G      1.772      1.327      1.259        591        640: 100%|██████████| 6/6 [00:01<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.508       0.72      0.532      0.275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50      3.63G      1.738      1.225      1.235        561        640: 100%|██████████| 6/6 [00:01<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.496      0.668      0.523      0.276\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50      5.37G      1.766       1.21      1.253        318        640: 100%|██████████| 6/6 [00:01<00:00,  4.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.529      0.555      0.524      0.264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50      5.46G       1.69      1.146      1.213        517        640: 100%|██████████| 6/6 [00:01<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.561      0.556      0.554      0.292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50      4.84G      1.749      1.135      1.215        390        640: 100%|██████████| 6/6 [00:01<00:00,  3.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.635      0.713      0.668      0.362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50      5.96G      1.769      1.113      1.236        374        640: 100%|██████████| 6/6 [00:01<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539       0.63      0.754      0.696      0.382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50      5.01G      1.764      1.101      1.224        587        640: 100%|██████████| 6/6 [00:01<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539        0.6      0.725       0.66      0.371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50      4.39G      1.695      1.083      1.208        367        640: 100%|██████████| 6/6 [00:01<00:00,  4.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.592      0.677      0.668       0.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50      4.64G       1.67      1.091      1.215        377        640: 100%|██████████| 6/6 [00:01<00:00,  3.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.511      0.611      0.598      0.339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50       5.2G      1.698      1.187      1.256        145        640: 100%|██████████| 6/6 [00:01<00:00,  3.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.513      0.616      0.591      0.328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50      4.35G      1.661      1.015      1.204        492        640: 100%|██████████| 6/6 [00:01<00:00,  4.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.607      0.715      0.709      0.374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50      4.52G      1.605     0.9705      1.197        275        640: 100%|██████████| 6/6 [00:01<00:00,  4.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.619      0.716      0.753      0.403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50      5.39G      1.622      1.001      1.173        424        640: 100%|██████████| 6/6 [00:01<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.668      0.789      0.794      0.407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50      5.75G      1.629     0.9839      1.186        513        640: 100%|██████████| 6/6 [00:01<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.685      0.748      0.782      0.424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50      5.37G      1.704      1.058      1.236        250        640: 100%|██████████| 6/6 [00:02<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.687       0.75      0.775      0.444\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/50      4.29G      1.715     0.9507      1.208        461        640: 100%|██████████| 6/6 [00:01<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.712      0.741      0.778      0.447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/50       3.5G       1.68     0.9603      1.206        543        640: 100%|██████████| 6/6 [00:01<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.679      0.741      0.754       0.42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50      5.02G      1.611     0.9812      1.173        956        640: 100%|██████████| 6/6 [00:01<00:00,  4.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.677      0.741      0.741      0.411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50      4.29G      1.605     0.9935      1.198        215        640: 100%|██████████| 6/6 [00:01<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.688      0.763      0.768      0.446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50       5.8G       1.63     0.9725      1.169        524        640: 100%|██████████| 6/6 [00:02<00:00,  2.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.712      0.776       0.79      0.458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50      4.11G      1.528     0.8919      1.156        315        640: 100%|██████████| 6/6 [00:01<00:00,  4.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.712      0.793      0.813      0.474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50      5.41G      1.555     0.9036      1.141        361        640: 100%|██████████| 6/6 [00:01<00:00,  3.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.797      0.698      0.807      0.476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50      3.95G      1.618      1.029      1.229        163        640: 100%|██████████| 6/6 [00:01<00:00,  4.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.749      0.736      0.778      0.466\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50      4.28G      1.599     0.9011      1.134        549        640: 100%|██████████| 6/6 [00:01<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.735      0.735      0.767      0.454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50      4.06G      1.577       0.88      1.153        458        640: 100%|██████████| 6/6 [00:01<00:00,  3.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.719      0.723      0.761      0.435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50      3.59G      1.664      1.022      1.212        427        640: 100%|██████████| 6/6 [00:03<00:00,  1.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.746      0.725      0.772      0.438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50      4.36G      1.539     0.9608      1.175        418        640: 100%|██████████| 6/6 [00:01<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539       0.71      0.774      0.797      0.447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50      3.66G      1.518     0.9674      1.162        389        640: 100%|██████████| 6/6 [00:01<00:00,  4.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.731      0.726      0.784      0.441\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50      3.72G      1.542     0.9831      1.218        166        640: 100%|██████████| 6/6 [00:01<00:00,  3.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.709      0.703      0.754      0.427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/50      4.05G       1.56     0.9418      1.214        257        640: 100%|██████████| 6/6 [00:01<00:00,  4.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.682      0.691      0.741      0.419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/50      3.33G      1.558     0.9216      1.175        417        640: 100%|██████████| 6/6 [00:01<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539       0.66        0.7      0.709      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/50      4.13G      1.537     0.9105      1.147        278        640: 100%|██████████| 6/6 [00:01<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.678      0.707      0.721      0.403\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/50      3.93G      1.491     0.9248      1.159        174        640: 100%|██████████| 6/6 [00:01<00:00,  4.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.686      0.717      0.739       0.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/50      3.86G      1.542     0.9106      1.153        407        640: 100%|██████████| 6/6 [00:01<00:00,  4.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.698       0.71      0.748      0.418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/50      3.71G      1.567     0.8944      1.193        244        640: 100%|██████████| 6/6 [00:01<00:00,  3.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.727      0.698      0.756      0.425\n",
            "\n",
            "50 epochs completed in 0.037 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.75 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.805      0.703      0.807      0.475\n",
            "                  Ramy          8        448      0.911      0.924      0.965      0.569\n",
            "               nonRamy          7         91      0.698      0.482      0.649      0.382\n",
            "Speed: 0.3ms preprocess, 2.0ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "Ultralytics 8.3.75 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/rayonnage/valid/labels.cache... 8 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          8        539      0.797      0.698      0.807      0.478\n",
            "                  Ramy          8        448      0.911      0.924      0.966      0.571\n",
            "               nonRamy          7         91      0.683      0.473      0.648      0.386\n",
            "Speed: 0.3ms preprocess, 12.6ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
            "\n",
            "image 1/1 /content/rayonnage/test/images/WhatsApp-Image-2025-02-05-a-10_07_51_81497b02_jpg.rf.ec7a60ce73b07828912115bc11e669d2.jpg: 640x640 83 Ramys, 7.4ms\n",
            "Speed: 2.3ms preprocess, 7.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"segmentation1.pt\")"
      ],
      "metadata": {
        "id": "TeZ0io9wGK2h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adISB99EBZW6",
        "outputId": "6ae8af7c-d0f4-45f1-a88d-21fef7bcaea8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Define path to uploaded dataset zip file\n",
        "zip_path = \"/content/rayonnage2.zip\"  # Change to your actual file name\n",
        "extract_path = \"/content/rayonnage2\"\n",
        "\n",
        "# Extract dataset\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"✅ Dataset extracted successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5y2rdrfA1Qa",
        "outputId": "fb2516cf-f20f-4e2e-8b78-c0655d84997a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset extracted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#image segmented visualisation\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Load the model\n",
        "model = YOLO(\"segmentation1.pt\")\n",
        "\n",
        "def process_image(image_path, output_dir=\"detected_segments\"):\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Read the image\n",
        "    original_image = cv2.imread(image_path)\n",
        "    visualization_image = original_image.copy()\n",
        "\n",
        "    # Get predictions\n",
        "    results = model.predict(source=image_path, save=False, conf=0.5)\n",
        "\n",
        "    # Generate random colors for visualization\n",
        "    np.random.seed(42)  # for consistent colors\n",
        "    colors = np.random.randint(0, 255, size=(100, 3)).tolist()\n",
        "\n",
        "    # Process each detection\n",
        "    for i, result in enumerate(results):\n",
        "        boxes = result.boxes\n",
        "        class_names = result.names  # Get class names from model\n",
        "\n",
        "        # Process each detected object\n",
        "        for j, box in enumerate(boxes):\n",
        "            # Get coordinates and information\n",
        "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "            conf = box.conf[0].cpu().numpy()\n",
        "            class_id = int(box.cls[0].cpu().numpy())\n",
        "\n",
        "            # Convert coordinates to integers\n",
        "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
        "\n",
        "            # Extract the segment\n",
        "            segment = original_image[y1:y2, x1:x2]\n",
        "\n",
        "            # Generate filename with timestamp and detection info\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"segment_{timestamp}_class{class_id}_conf{conf:.2f}.jpg\"\n",
        "            output_path = os.path.join(output_dir, filename)\n",
        "\n",
        "            # Save the segment\n",
        "            cv2.imwrite(output_path, segment)\n",
        "\n",
        "            # Draw box and label on visualization image\n",
        "            color = colors[class_id % len(colors)]\n",
        "\n",
        "            # Draw filled rectangle for label background\n",
        "            label = f\"{class_names[class_id]} {conf:.2f}\"\n",
        "            (label_width, label_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
        "            cv2.rectangle(visualization_image, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.rectangle(visualization_image, (x1, y1 - label_height - 10), (x1 + label_width + 10, y1), color, -1)\n",
        "\n",
        "            # Draw label text\n",
        "            cv2.putText(visualization_image, label, (x1 + 5, y1 - 5),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "            print(f\"Saved segment {j+1} to {output_path}\")\n",
        "\n",
        "    # Save the visualization image\n",
        "    vis_output_path = os.path.join(output_dir, \"visualization.jpg\")\n",
        "    cv2.imwrite(vis_output_path, visualization_image)\n",
        "    print(f\"Saved visualization to {vis_output_path}\")\n",
        "\n",
        "    return visualization_image\n",
        "\n",
        "# Use the function\n",
        "image_path = \"/content/rayonnage/valid/images/pdv_pic_609921_1738747909780_98552_png.rf.63d7820ee51e72196cc037f11d44b8aa.jpg\"\n",
        "labeled_image = process_image(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq8NvNExTU70",
        "outputId": "aad4d9bf-bbeb-4400-8a63-4190396553d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/rayonnage/valid/images/pdv_pic_609921_1738747909780_98552_png.rf.63d7820ee51e72196cc037f11d44b8aa.jpg: 640x640 20 Ramys, 18 nonRamys, 9.4ms\n",
            "Speed: 2.5ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Saved segment 1 to detected_segments/segment_20250215_015746_class1_conf0.88.jpg\n",
            "Saved segment 2 to detected_segments/segment_20250215_015746_class1_conf0.86.jpg\n",
            "Saved segment 3 to detected_segments/segment_20250215_015746_class1_conf0.86.jpg\n",
            "Saved segment 4 to detected_segments/segment_20250215_015746_class1_conf0.84.jpg\n",
            "Saved segment 5 to detected_segments/segment_20250215_015746_class1_conf0.84.jpg\n",
            "Saved segment 6 to detected_segments/segment_20250215_015746_class1_conf0.83.jpg\n",
            "Saved segment 7 to detected_segments/segment_20250215_015746_class1_conf0.80.jpg\n",
            "Saved segment 8 to detected_segments/segment_20250215_015746_class1_conf0.80.jpg\n",
            "Saved segment 9 to detected_segments/segment_20250215_015746_class0_conf0.78.jpg\n",
            "Saved segment 10 to detected_segments/segment_20250215_015746_class1_conf0.75.jpg\n",
            "Saved segment 11 to detected_segments/segment_20250215_015746_class1_conf0.75.jpg\n",
            "Saved segment 12 to detected_segments/segment_20250215_015746_class1_conf0.74.jpg\n",
            "Saved segment 13 to detected_segments/segment_20250215_015746_class1_conf0.73.jpg\n",
            "Saved segment 14 to detected_segments/segment_20250215_015746_class0_conf0.73.jpg\n",
            "Saved segment 15 to detected_segments/segment_20250215_015747_class1_conf0.72.jpg\n",
            "Saved segment 16 to detected_segments/segment_20250215_015747_class1_conf0.72.jpg\n",
            "Saved segment 17 to detected_segments/segment_20250215_015747_class0_conf0.68.jpg\n",
            "Saved segment 18 to detected_segments/segment_20250215_015747_class1_conf0.67.jpg\n",
            "Saved segment 19 to detected_segments/segment_20250215_015747_class0_conf0.67.jpg\n",
            "Saved segment 20 to detected_segments/segment_20250215_015747_class1_conf0.66.jpg\n",
            "Saved segment 21 to detected_segments/segment_20250215_015747_class1_conf0.64.jpg\n",
            "Saved segment 22 to detected_segments/segment_20250215_015747_class0_conf0.60.jpg\n",
            "Saved segment 23 to detected_segments/segment_20250215_015747_class0_conf0.59.jpg\n",
            "Saved segment 24 to detected_segments/segment_20250215_015747_class0_conf0.58.jpg\n",
            "Saved segment 25 to detected_segments/segment_20250215_015747_class0_conf0.58.jpg\n",
            "Saved segment 26 to detected_segments/segment_20250215_015747_class0_conf0.57.jpg\n",
            "Saved segment 27 to detected_segments/segment_20250215_015747_class0_conf0.57.jpg\n",
            "Saved segment 28 to detected_segments/segment_20250215_015747_class0_conf0.56.jpg\n",
            "Saved segment 29 to detected_segments/segment_20250215_015747_class0_conf0.56.jpg\n",
            "Saved segment 30 to detected_segments/segment_20250215_015747_class0_conf0.55.jpg\n",
            "Saved segment 31 to detected_segments/segment_20250215_015747_class0_conf0.55.jpg\n",
            "Saved segment 32 to detected_segments/segment_20250215_015747_class0_conf0.55.jpg\n",
            "Saved segment 33 to detected_segments/segment_20250215_015747_class0_conf0.54.jpg\n",
            "Saved segment 34 to detected_segments/segment_20250215_015747_class0_conf0.53.jpg\n",
            "Saved segment 35 to detected_segments/segment_20250215_015747_class0_conf0.53.jpg\n",
            "Saved segment 36 to detected_segments/segment_20250215_015747_class1_conf0.53.jpg\n",
            "Saved segment 37 to detected_segments/segment_20250215_015747_class0_conf0.52.jpg\n",
            "Saved segment 38 to detected_segments/segment_20250215_015747_class0_conf0.52.jpg\n",
            "Saved visualization to detected_segments/visualization.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ramy segments save\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def save_ramy_segments(image_path, results, output_dir):\n",
        "    \"\"\"\n",
        "    Save segments from detection results only if they are Ramy products and count products.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the original image\n",
        "        results: YOLOv8 detection results (from model.predict())\n",
        "        output_dir (str): Directory where to save the segments\n",
        "\n",
        "    Returns:\n",
        "        tuple: (list of saved paths, dict of counts)\n",
        "    \"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Read the original image\n",
        "    image = cv2.imread(str(image_path))\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Could not read image at {image_path}\")\n",
        "\n",
        "    saved_paths = []\n",
        "\n",
        "    # Initialize counters\n",
        "    counts = {\n",
        "        'total_products': 0,\n",
        "        'ramy_products': 0\n",
        "    }\n",
        "\n",
        "    # Get the first result (if running on a single image)\n",
        "    result = results[0] if isinstance(results, list) else results\n",
        "\n",
        "    # Count total products\n",
        "    if hasattr(result, 'boxes') and result.boxes is not None:\n",
        "        counts['total_products'] = len(result.boxes)\n",
        "\n",
        "    # Check if we have any masks\n",
        "    if not hasattr(result, 'masks') or result.masks is None:\n",
        "        print(f\"No segments found in {image_path}\")\n",
        "        return saved_paths, counts\n",
        "\n",
        "    # Process each detection\n",
        "    for i, seg in enumerate(result.masks.segments):\n",
        "        # Get the class ID for this detection\n",
        "        class_id = int(result.boxes.cls[i])\n",
        "\n",
        "        # Check if this is a Ramy product (assuming class_id 0 is Ramy based on your names list)\n",
        "        if class_id == 0:  # Ramy class\n",
        "            counts['ramy_products'] += 1\n",
        "\n",
        "            # Convert segment points to numpy array\n",
        "            segment = np.array(seg, dtype=np.int32)\n",
        "\n",
        "            # Create a mask for this segment\n",
        "            mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
        "            cv2.fillPoly(mask, [segment], 255)\n",
        "\n",
        "            # Extract the segment\n",
        "            segment_image = cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "            # Get bounding box of the segment to crop\n",
        "            x, y, w, h = cv2.boundingRect(segment)\n",
        "            cropped_segment = segment_image[y:y+h, x:x+w]\n",
        "\n",
        "            # Generate output filename\n",
        "            output_path = output_dir / f\"ramy_segment_{i}_{Path(image_path).stem}.jpg\"\n",
        "\n",
        "            # Save the segment\n",
        "            cv2.imwrite(str(output_path), cropped_segment)\n",
        "            saved_paths.append(output_path)\n",
        "\n",
        "    return saved_paths, counts\n",
        "\n",
        "# Example of how to use the function:\n",
        "def process_image(model_path, image_path, output_dir):\n",
        "    # Load the YOLOv8 model\n",
        "    model = YOLO(model_path)  # Path to your trained model .pt file\n",
        "\n",
        "    # Run detection with segmentation\n",
        "    results = model.predict(\n",
        "        source=image_path,\n",
        "        save=False,  # Don't save the basic YOLO results\n",
        "        conf=0.25,   # Confidence threshold\n",
        "        iou=0.45,    # NMS IoU threshold\n",
        "        mode='segment'  # Run in segmentation mode\n",
        "    )\n",
        "\n",
        "    # Save only Ramy segments\n",
        "    saved_segments = save_ramy_segments(image_path, results, output_dir)\n",
        "    print(f\"Saved {len(saved_segments)} Ramy segments\")\n",
        "    return saved_segments\n",
        "\n",
        "# Usage example:\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = \"/content/segmentation1.pt\"  # Your trained model\n",
        "    image_path = \"/content/rayonnage/valid/images/pdv_pic_609921_1738747909780_98552_png.rf.63d7820ee51e72196cc037f11d44b8aa.jpg\"\n",
        "    output_dir = \"/content/detected_segments\"\n",
        "\n",
        "    saved_files = process_image(model_path, image_path, output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFzUjWajXghh",
        "outputId": "3bedcd14-8978-47c2-99f2-21c131f4b2b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/rayonnage/valid/images/pdv_pic_609921_1738747909780_98552_png.rf.63d7820ee51e72196cc037f11d44b8aa.jpg: 640x640 30 Ramys, 27 nonRamys, 9.2ms\n",
            "Speed: 7.4ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No segments found in /content/rayonnage/valid/images/pdv_pic_609921_1738747909780_98552_png.rf.63d7820ee51e72196cc037f11d44b8aa.jpg\n",
            "Saved 0 Ramy segments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "def analyze_shelves(results, tolerance=50):\n",
        "    \"\"\"\n",
        "    Analyze detection results to identify shelves and count products per shelf.\n",
        "\n",
        "    Args:\n",
        "        results: YOLOv8 detection results\n",
        "        tolerance: Vertical distance (pixels) to consider products on the same shelf\n",
        "\n",
        "    Returns:\n",
        "        list: List of shelf dictionaries containing position and product counts\n",
        "    \"\"\"\n",
        "    result = results[0] if isinstance(results, list) else results\n",
        "\n",
        "    if not hasattr(result, 'boxes') or result.boxes is None:\n",
        "        return []\n",
        "\n",
        "    # Extract all bounding boxes and their classes\n",
        "    boxes = []\n",
        "    for i in range(len(result.boxes)):\n",
        "        box = result.boxes[i]\n",
        "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()  # Get box coordinates\n",
        "        class_id = int(box.cls[0])\n",
        "        center_y = (y1 + y2) / 2\n",
        "        boxes.append({\n",
        "            'center_y': center_y,\n",
        "            'class_id': class_id,\n",
        "            'bbox': (x1, y1, x2, y2)\n",
        "        })\n",
        "\n",
        "    # Sort boxes by vertical position\n",
        "    boxes.sort(key=lambda x: x['center_y'])\n",
        "\n",
        "    # Group boxes into shelves based on vertical position\n",
        "    shelves = []\n",
        "    current_shelf = []\n",
        "    current_y = None\n",
        "\n",
        "    for box in boxes:\n",
        "        if current_y is None:\n",
        "            current_y = box['center_y']\n",
        "            current_shelf.append(box)\n",
        "        elif abs(box['center_y'] - current_y) <= tolerance:\n",
        "            current_shelf.append(box)\n",
        "        else:\n",
        "            # Process completed shelf\n",
        "            if current_shelf:\n",
        "                shelves.append(process_shelf(current_shelf))\n",
        "            # Start new shelf\n",
        "            current_shelf = [box]\n",
        "            current_y = box['center_y']\n",
        "\n",
        "    # Process last shelf\n",
        "    if current_shelf:\n",
        "        shelves.append(process_shelf(current_shelf))\n",
        "\n",
        "    return shelves\n",
        "\n",
        "def process_shelf(shelf_boxes):\n",
        "    \"\"\"\n",
        "    Process boxes in a shelf to count products by type.\n",
        "\n",
        "    Args:\n",
        "        shelf_boxes: List of boxes on the same shelf\n",
        "\n",
        "    Returns:\n",
        "        dict: Shelf information including product counts and position\n",
        "    \"\"\"\n",
        "    ramy_count = sum(1 for box in shelf_boxes if box['class_id'] == 0)\n",
        "    other_count = sum(1 for box in shelf_boxes if box['class_id'] == 1)\n",
        "\n",
        "    # Calculate shelf boundaries\n",
        "    y_positions = [box['center_y'] for box in shelf_boxes]\n",
        "    bboxes = [box['bbox'] for box in shelf_boxes]\n",
        "    x_positions = [(box[0], box[2]) for box in bboxes]\n",
        "\n",
        "    shelf_info = {\n",
        "        'y_position': np.mean(y_positions),\n",
        "        'x_range': (min(x[0] for x in x_positions), max(x[1] for x in x_positions)),\n",
        "        'ramy_count': ramy_count,\n",
        "        'other_count': other_count,\n",
        "        'total_count': len(shelf_boxes)\n",
        "    }\n",
        "\n",
        "    return shelf_info\n",
        "\n",
        "def visualize_shelves(image_path, results, shelves):\n",
        "    \"\"\"\n",
        "    Visualize detected shelves and their product counts on the image.\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the original image\n",
        "        results: YOLOv8 detection results\n",
        "        shelves: List of shelf information\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Annotated image\n",
        "    \"\"\"\n",
        "    # Read image\n",
        "    image = cv2.imread(str(image_path))\n",
        "\n",
        "    # Draw shelf lines and counts\n",
        "    for i, shelf in enumerate(shelves):\n",
        "        y = int(shelf['y_position'])\n",
        "        x1, x2 = int(shelf['x_range'][0]), int(shelf['x_range'][1])\n",
        "\n",
        "        # Draw shelf line\n",
        "        cv2.line(image, (x1, y), (x2, y), (0, 255, 0), 2)\n",
        "\n",
        "        # Add shelf number and counts\n",
        "        text = f\"Shelf {i+1}: Ramy={shelf['ramy_count']}, Other={shelf['other_count']}\"\n",
        "        cv2.putText(image, text, (x1, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "    return image\n",
        "\n",
        "def analyze_store_shelves(model_path, image_path, output_dir):\n",
        "    \"\"\"\n",
        "    Analyze store shelves and save visualized results.\n",
        "\n",
        "    Args:\n",
        "        model_path: Path to trained YOLOv8 model\n",
        "        image_path: Path to image to analyze\n",
        "        output_dir: Directory to save results\n",
        "\n",
        "    Returns:\n",
        "        tuple: (List of shelf information, Path to visualized result)\n",
        "    \"\"\"\n",
        "    # Create output directory\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Load model and run detection\n",
        "    model = YOLO(model_path)\n",
        "    results = model.predict(source=image_path, save=False, conf=0.25)\n",
        "\n",
        "    # Analyze shelves\n",
        "    shelves = analyze_shelves(results)\n",
        "\n",
        "    # Create visualization\n",
        "    annotated_image = visualize_shelves(image_path, results, shelves)\n",
        "\n",
        "    # Save visualized result\n",
        "    output_path = output_dir / f\"analyzed_{Path(image_path).stem}.jpg\"\n",
        "    cv2.imwrite(str(output_path), annotated_image)\n",
        "\n",
        "    return shelves, output_path\n",
        "\n",
        "# Example usage:\n",
        "model_path = \"/content/segmentation1.pt\"\n",
        "image_path = \"/content/rayonnage/valid/images/pdv_pic_609921_1738747909780_98552_png.rf.63d7820ee51e72196cc037f11d44b8aa.jpg\"\n",
        "output_dir = \"/content/shelves\"\n",
        "\n",
        "shelves, output_image = analyze_store_shelves(model_path, image_path, output_dir)\n",
        "\n",
        "# Print analysis results\n",
        "for i, shelf in enumerate(shelves, 1):\n",
        "    print(f\"\\nShelf {i}:\")\n",
        "    print(f\"Ramy products: {shelf['ramy_count']}\")\n",
        "    print(f\"Other products: {shelf['other_count']}\")\n",
        "    print(f\"Total products: {shelf['total_count']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0XIu5AGhiMd",
        "outputId": "482b6271-f18a-4fb9-d1d1-1d0d35553484"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/rayonnage/valid/images/pdv_pic_609921_1738747909780_98552_png.rf.63d7820ee51e72196cc037f11d44b8aa.jpg: 640x640 30 Ramys, 27 nonRamys, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Shelf 1:\n",
            "Ramy products: 9\n",
            "Other products: 2\n",
            "Total products: 11\n",
            "\n",
            "Shelf 2:\n",
            "Ramy products: 4\n",
            "Other products: 4\n",
            "Total products: 8\n",
            "\n",
            "Shelf 3:\n",
            "Ramy products: 7\n",
            "Other products: 4\n",
            "Total products: 11\n",
            "\n",
            "Shelf 4:\n",
            "Ramy products: 0\n",
            "Other products: 9\n",
            "Total products: 9\n",
            "\n",
            "Shelf 5:\n",
            "Ramy products: 2\n",
            "Other products: 7\n",
            "Total products: 9\n",
            "\n",
            "Shelf 6:\n",
            "Ramy products: 8\n",
            "Other products: 1\n",
            "Total products: 9\n"
          ]
        }
      ]
    }
  ]
}